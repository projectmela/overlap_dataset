{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b00999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30c7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Annotation set\n",
    "anno_set = 'Set 1/'\n",
    "\n",
    "## Names of files where mapping is being performed\n",
    "file1 = '20230313_SE_Lek1_P2D3_DJI_0312'\n",
    "file2 = '20230313_SE_Lek1_P3D5_DJI_0575'\n",
    "\n",
    "## Names of files compressed\n",
    "f1 = 'P2D3_DJI_0312'\n",
    "f2 = 'P3D5_DJI_0575'\n",
    "\n",
    "## Column names used often\n",
    "start_frame1 = 'start_frame_' + f1\n",
    "start_frame2 = 'start_frame_' + f2\n",
    "end_frame1 = 'end_frame_' + f1\n",
    "end_frame2 = 'end_frame_' + f2\n",
    "Frame1 = 'Frame_' + f1\n",
    "Frame2 = 'Frame_' + f2\n",
    "ID1 = 'ID_' + f1\n",
    "ID2 = 'ID_' + f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3feafe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read dataframes for both files\n",
    "df1 = pd.read_csv('/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Code/Python/OpenCV/plot_tracks/data/' + file1 + '_tracks.csv')\n",
    "df1 = df1.loc[:,['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height']]\n",
    "df2 = pd.read_csv('/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Code/Python/OpenCV/plot_tracks/data/' + file2 + '_tracks.csv')\n",
    "df2 = df2.loc[:,['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height']]\n",
    "\n",
    "## Read the manually created mapping file\n",
    "map_df = pd.read_csv('/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Manuscripts/10_dataset/Data/' + anno_set + 'Mapping_' + file1 + '_' + file2 + '.csv', sep=';')\n",
    "map_df.columns = [Frame1, ID1, Frame2, ID2]\n",
    "\n",
    "## Frame mapping for overlap (vid2 - vid1) e.g. vid2(399) == vid1(396)\n",
    "lag = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02635a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Incorporate lag in the tracking data\n",
    "if lag > 0:\n",
    "    df1['lagged_frame'] = df1['frame']\n",
    "    df2['lagged_frame'] = df2['frame'] + lag\n",
    "elif lag < 0:\n",
    "    df1['lagged_frame'] = df1['frame'] + lag\n",
    "    df2['lagged_frame'] = df2['frame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48e2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to find min and max in an array within the 'current chain'\n",
    "def find_chain_min_max(array, element):\n",
    "    ## Find the index of the given element in the array\n",
    "    index = np.where(array == element)[0][0]\n",
    "    \n",
    "    ## Find the starting index of the consecutive chain\n",
    "    start_index = index\n",
    "    while start_index > 0 and array[start_index] - array[start_index - 1] == 1:\n",
    "        start_index -= 1\n",
    "    \n",
    "    ## Find the ending index of the consecutive chain\n",
    "    end_index = index\n",
    "    while end_index < len(array) - 1 and array[end_index + 1] - array[end_index] == 1:\n",
    "        end_index += 1\n",
    "    \n",
    "    ## Return the minimum and maximum within the consecutive chain\n",
    "    return array[start_index], array[end_index]\n",
    "\n",
    "## Function to calculate overlap frames\n",
    "def calculate_overlap(row):\n",
    "    start_overlap = max(row[start_frame1], row[start_frame2])\n",
    "    end_overlap = min(row[end_frame1], row[end_frame2])\n",
    "    if start_overlap <= end_overlap:\n",
    "        return pd.Series([start_overlap, end_overlap])\n",
    "    else:\n",
    "        return pd.Series([None, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb850c77",
   "metadata": {},
   "source": [
    "### Make a dataframe that has the same rows as  'map_df' but includes start and end frames of each ID in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e251efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ready new mapping dataframe with start and end frames for each ID\n",
    "for index, row in map_df.iterrows():\n",
    "    ## Get tracklets from current row\n",
    "    tracklet1 = df1[df1['id'] == row[ID1]]\n",
    "    tracklet2 = df2[df2['id'] == row[ID2]]\n",
    "    \n",
    "    ## Get start and end frame of tracklets based on annotated frame\n",
    "    anno_fr1 = row[Frame1]\n",
    "    anno_fr2 = row[Frame2]\n",
    "    \n",
    "    start_fr1, end_fr1 = find_chain_min_max(np.array(tracklet1['frame']), anno_fr1)\n",
    "    start_fr2, end_fr2 = find_chain_min_max(np.array(tracklet2['frame']), anno_fr2)\n",
    "    \n",
    "    ## Compile modified dataframe\n",
    "    tmp = pd.DataFrame([start_fr1, end_fr1, row[ID1], start_fr2, end_fr2, row[ID2]]).T\n",
    "    tmp.columns = [start_frame1, end_frame1, ID1, start_frame2, end_frame2, ID2]\n",
    "    if index != 0:\n",
    "        df = pd.concat((df, tmp), axis=0)\n",
    "    else:\n",
    "        df = tmp\n",
    "        \n",
    "df = df.reset_index(drop = True)\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651eda8f",
   "metadata": {},
   "source": [
    "Errors detected were manually deleted in the mapping file. Below, I list the errors I found during my process of checking mapping quality.\n",
    "1. ID 77 in P2D3_0312 mapped to ID 44 in P3D5_0575 \n",
    "2. ID 161 in P1D1_0294 mapped to ID 65 in P2D3_0310\n",
    "3. ID 130 in P2D4_0940 mapped to ID 85 in P3D6_0923\n",
    "4. ID 137 in P2D4_0940 mapped to ID 86 in P3D6_0923\n",
    "5. ID 11 in P2D4_0940 mapped to ID 87 in P3D6_0923\n",
    "\n",
    "These rows were deleted because the frame indicated in the map_df dataframe was outside of the life of the corresponding ID.\n",
    "I also manually added lines at the end of the mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b53093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_frame_P2D3_DJI_0312</th>\n",
       "      <th>end_frame_P2D3_DJI_0312</th>\n",
       "      <th>ID_P2D3_DJI_0312</th>\n",
       "      <th>start_frame_P3D5_DJI_0575</th>\n",
       "      <th>end_frame_P3D5_DJI_0575</th>\n",
       "      <th>ID_P3D5_DJI_0575</th>\n",
       "      <th>start_frame_overlap</th>\n",
       "      <th>end_frame_overlap</th>\n",
       "      <th>start_frame_lag</th>\n",
       "      <th>end_frame_lag</th>\n",
       "      <th>lag_overlap_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5813.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5813.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>1501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1509.0</td>\n",
       "      <td>5814.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5813.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>5813.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>5810.0</td>\n",
       "      <td>4299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_frame_P2D3_DJI_0312  end_frame_P2D3_DJI_0312  ID_P2D3_DJI_0312  \\\n",
       "0                        0.0                      7.0              61.0   \n",
       "1                        0.0                     32.0              55.0   \n",
       "2                        0.0                     72.0               8.0   \n",
       "3                        0.0                   1503.0               7.0   \n",
       "4                     1509.0                   5814.0             136.0   \n",
       "\n",
       "   start_frame_P3D5_DJI_0575  end_frame_P3D5_DJI_0575  ID_P3D5_DJI_0575  \\\n",
       "0                        0.0                    840.0              21.0   \n",
       "1                        0.0                   5813.0              18.0   \n",
       "2                        0.0                   3238.0              11.0   \n",
       "3                        0.0                   5813.0              10.0   \n",
       "4                        0.0                   5813.0              10.0   \n",
       "\n",
       "   start_frame_overlap  end_frame_overlap  start_frame_lag  end_frame_lag  \\\n",
       "0                  0.0                7.0              3.0            7.0   \n",
       "1                  0.0               32.0              3.0           32.0   \n",
       "2                  0.0               72.0              3.0           72.0   \n",
       "3                  0.0             1503.0              3.0         1503.0   \n",
       "4               1509.0             5813.0           1512.0         5810.0   \n",
       "\n",
       "   lag_overlap_duration  \n",
       "0                   5.0  \n",
       "1                  30.0  \n",
       "2                  70.0  \n",
       "3                1501.0  \n",
       "4                4299.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calculate overlap between the two videos\n",
    "overlap_frames = df.apply(calculate_overlap, axis=1)\n",
    "overlap_frames.columns = ['start_frame_overlap', 'end_frame_overlap']\n",
    "\n",
    "## Add the calculated overlap frames to the original DataFrame\n",
    "df = pd.concat([df, overlap_frames], axis=1)\n",
    "\n",
    "## Apply lag to the overlap window as appropriate\n",
    "## Here, we assume that vid1 needs addition of 'lag' frames to match frame numbers with vid2\n",
    "## If start_frame_vid1 >= start_frame_vid2: start_frame_lag = start_frame_overlap + lag\n",
    "df['start_frame_lag'] = df['start_frame_overlap']\n",
    "df.loc[df[start_frame1] >= df[start_frame2], 'start_frame_lag'] += 3\n",
    "df['end_frame_lag'] = df['end_frame_overlap']\n",
    "df.loc[df[end_frame1] >= df[end_frame2], 'end_frame_lag'] -= 3\n",
    "df['lag_overlap_duration'] = df['end_frame_lag'] - df['start_frame_lag'] + 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc54ece",
   "metadata": {},
   "source": [
    "### Plot videos of the two videos with colours to indicate corresponding tracklets in the two videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6b8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get paths and parameters for creating the output videos\n",
    "input_vidpath1 = '/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Code/Python/OpenCV/plot_tracks/data/' + file1 + '.MP4'\n",
    "input_vidpath2 = '/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Code/Python/OpenCV/plot_tracks/data/' + file2 + '.MP4'\n",
    "output_vidpath1 = '/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Code/Python/OpenCV/plot_tracks/output/tracks/' + anno_set + file1 + '_frameno.mp4'\n",
    "output_vidpath2 = '/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Code/Python/OpenCV/plot_tracks/output/tracks/' + anno_set + file2 + '_frameno.mp4'\n",
    "output_vidpath_merged = '/Users/vivekhsridhar/Library/Mobile Documents/com~apple~CloudDocs/Documents/Code/Python/OpenCV/plot_tracks/output/tracks/' anno_set + file1 + '_' + file2 + '_merged.mp4'\n",
    "codec = 'DIVX'\n",
    "scaling = 0.5\n",
    "\n",
    "## Plotting parameters\n",
    "max_radius = 5\n",
    "frame_range = 100\n",
    "col_mult = int(255/len(df))\n",
    "colours = [(i*col_mult,255,255) for i in range(len(df))]\n",
    "\n",
    "## Include the colour column to df\n",
    "df['colour'] = colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73f19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate positions of all individuals in both videos\n",
    "df1['pos_x'] = (df1['bb_left'] + df1['bb_width']/2)*scaling\n",
    "df1['pos_y'] = (df1['bb_top'] + df1['bb_height']/2)*scaling\n",
    "df2['pos_x'] = (df2['bb_left'] + df2['bb_width']/2)*scaling\n",
    "df2['pos_y'] = (df2['bb_top'] + df2['bb_height']/2)*scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10b381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write output video 1\n",
    "## Open video\n",
    "cap = cv2.VideoCapture(input_vidpath1)\n",
    "if cap.isOpened() == False:\n",
    "    sys.exit('Video file cannot be read! Please check input_vidpath to ensure it is correctly pointing to the video file')\n",
    "\n",
    "## Video writer class to output video with contour and centroid of tracked object(s)\n",
    "# make sure the frame size matches size of array 'final'\n",
    "fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "output_framesize = (int(cap.read()[1].shape[1]*scaling),int(cap.read()[1].shape[0]*scaling))\n",
    "out = cv2.VideoWriter(filename = output_vidpath1, fourcc = fourcc, fps = 30.0, frameSize = output_framesize, isColor = True)\n",
    "\n",
    "last = 0\n",
    "\n",
    "while(True):\n",
    "    ## Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    this = cap.get(1)\n",
    "    \n",
    "    if ret == True:\n",
    "        ## Preprocess the image for background subtraction\n",
    "        frame = cv2.resize(frame, None, fx=scaling, fy=scaling, interpolation=cv2.INTER_LINEAR)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        ## Filter objects of interest based on the current frame\n",
    "#         if lag > 0:\n",
    "#             filtered_df = df[(df['start_frame_lag'] <= this) & (df['end_frame_overlap'] >= this)]\n",
    "#         else:\n",
    "#             filtered_df = df[(df['start_frame_overlap'] <= this) & (df['end_frame_lag'] >= this)]\n",
    "#         if filtered_df.empty == False:\n",
    "#             indices, interested_objects = zip(*[(idx, row[ID1]) for idx, row in filtered_df.iterrows()])\n",
    "\n",
    "#             ## Filter MOT dataframe based on the current frame and interested objects\n",
    "#             tmp = df1[(df1['frame'] == this) & (df1['id'].isin(interested_objects))]\n",
    "#             tmp = tmp.reset_index()\n",
    "            \n",
    "#             if len(filtered_df) != len(tmp):\n",
    "#                 print('no')\n",
    "#                 break\n",
    "            \n",
    "#             for i in range(0,len(tmp)):\n",
    "#                 x = int(tmp.loc[i,'pos_x'])\n",
    "#                 y = int(tmp.loc[i,'pos_y'])\n",
    "#                 r = int(max_radius - (this - tmp.loc[i,'frame'])//(frame_range/max_radius))\n",
    "#                 c = df.loc[indices[np.where(interested_objects == tmp.loc[i,'id'])[0][0]], 'colour']\n",
    "#                 cv2.circle(frame, (x,y), r, c, -1, cv2.LINE_AA)\n",
    "#                 cv2.putText(frame, str(int(tmp.loc[i,'id'])), (x+20,y-20), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.putText(frame, str(this), (20,50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        ## Display the resulting frame\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "            \n",
    "    if last >= this:\n",
    "        break\n",
    "    \n",
    "    last = this\n",
    "\n",
    "## When everything done, release the capture\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae29b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write output video 2\n",
    "## Open video\n",
    "cap = cv2.VideoCapture(input_vidpath2)\n",
    "if cap.isOpened() == False:\n",
    "    sys.exit('Video file cannot be read! Please check input_vidpath to ensure it is correctly pointing to the video file')\n",
    "\n",
    "## Video writer class to output video with contour and centroid of tracked object(s)\n",
    "# make sure the frame size matches size of array 'final'\n",
    "fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "output_framesize = (int(cap.read()[1].shape[1]*scaling),int(cap.read()[1].shape[0]*scaling))\n",
    "out = cv2.VideoWriter(filename = output_vidpath2, fourcc = fourcc, fps = 30.0, frameSize = output_framesize, isColor = True)\n",
    "\n",
    "last = 0\n",
    "\n",
    "while(True):\n",
    "    ## Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    this = cap.get(1)\n",
    "    \n",
    "    if ret == True:\n",
    "        ## Preprocess the image for background subtraction\n",
    "        frame = cv2.resize(frame, None, fx=scaling, fy=scaling, interpolation=cv2.INTER_LINEAR)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        ## Filter objects of interest based on the current frame\n",
    "#         if lag > 0:\n",
    "#             filtered_df = df[(df['start_frame_overlap'] <= this) & (df['end_frame_lag'] >= this)]\n",
    "#         else:\n",
    "#             filtered_df = df[(df['start_frame_lag'] <= this) & (df['end_frame_overlap'] >= this)]\n",
    "#         if filtered_df.empty == False:\n",
    "#             indices, interested_objects = zip(*[(idx, row[ID2]) for idx, row in filtered_df.iterrows()])\n",
    "\n",
    "#             ## Filter MOT dataframe based on the current frame and interested objects\n",
    "#             tmp = df2[(df2['frame'] == this) & (df2['id'].isin(interested_objects))]\n",
    "#             tmp = tmp.reset_index()\n",
    "\n",
    "#             for i in range(0,len(tmp)):\n",
    "#                 x = int(tmp.loc[i,'pos_x'])\n",
    "#                 y = int(tmp.loc[i,'pos_y'])\n",
    "#                 r = int(max_radius - (this - tmp.loc[i,'frame'])//(frame_range/max_radius))\n",
    "#                 c = df.loc[indices[np.where(interested_objects == tmp.loc[i,'id'])[0][0]], 'colour']\n",
    "#                 cv2.circle(frame, (x,y), r, c, -1, cv2.LINE_AA)\n",
    "#                 cv2.putText(frame, str(int(tmp.loc[i,'id'])), (x+20,y-20), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.putText(frame, str(this), (20,50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        ## Display the resulting frame\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "            \n",
    "    if last >= this:\n",
    "        break\n",
    "    \n",
    "    last = this\n",
    "\n",
    "## When everything done, release the capture\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fd265ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write the concatenated video\n",
    "## Open the two videos\n",
    "cap1 = cv2.VideoCapture(output_vidpath1)\n",
    "if not cap1.isOpened():\n",
    "    sys.exit('Video file 1 cannot be read! Please check input_vidpath1 to ensure it is correctly pointing to the video file')\n",
    "\n",
    "cap2 = cv2.VideoCapture(output_vidpath2)\n",
    "if not cap2.isOpened():\n",
    "    sys.exit('Video file 2 cannot be read! Please check input_vidpath2 to ensure it is correctly pointing to the video file')\n",
    "\n",
    "## Video writer class to output concatenated video\n",
    "fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "frame_width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH) * scaling)\n",
    "frame_height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT) * scaling)\n",
    "output_framesize = (frame_width, frame_height * 2)\n",
    "out = cv2.VideoWriter(filename=output_vidpath_merged, fourcc=fourcc, fps=30.0, frameSize=output_framesize, isColor=True)\n",
    "\n",
    "## Create a black frame for the delayed video\n",
    "black_frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "## Buffer to store initial frames of the delayed video\n",
    "buffer = []\n",
    "buffer_size = abs(lag)  # Adjust buffer size based on the absolute value of lag\n",
    "\n",
    "## Pre-fill buffer with initial frames of Video 2 if lag is positive, else pre-fill buffer with Video 1 frames\n",
    "if lag < 0:\n",
    "    for _ in range(buffer_size):\n",
    "        ret2, frame2 = cap2.read()\n",
    "        if not ret2:\n",
    "            break\n",
    "        frame2 = cv2.resize(frame2, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
    "        buffer.append(frame2)\n",
    "elif lag > 0:\n",
    "    for _ in range(buffer_size):\n",
    "        ret1, frame1 = cap1.read()\n",
    "        if not ret1:\n",
    "            break\n",
    "        frame1 = cv2.resize(frame1, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
    "        buffer.append(frame1)\n",
    "\n",
    "## Loop through frames of both videos simultaneously and concatenate vertically\n",
    "frame_counter = 0\n",
    "while True:\n",
    "    if lag < 0:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        if not ret1:\n",
    "            frame1 = black_frame\n",
    "        else:\n",
    "            frame1 = cv2.resize(frame1, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
    "            if frame_counter < buffer_size:\n",
    "                frame2 = black_frame\n",
    "            else:\n",
    "                frame2 = buffer.pop(0)\n",
    "                ret2, new_frame2 = cap2.read()\n",
    "                if ret2:\n",
    "                    new_frame2 = cv2.resize(new_frame2, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
    "                    buffer.append(new_frame2)\n",
    "                else:\n",
    "                    frame2 = black_frame\n",
    "    elif lag > 0:\n",
    "        ret2, frame2 = cap2.read()\n",
    "        if not ret2:\n",
    "            frame2 = black_frame\n",
    "        else:\n",
    "            frame2 = cv2.resize(frame2, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
    "            if frame_counter < buffer_size:\n",
    "                frame1 = black_frame\n",
    "            else:\n",
    "                frame1 = buffer.pop(0)\n",
    "                ret1, new_frame1 = cap1.read()\n",
    "                if ret1:\n",
    "                    new_frame1 = cv2.resize(new_frame1, (frame_width, frame_height), interpolation=cv2.INTER_LINEAR)\n",
    "                    buffer.append(new_frame1)\n",
    "                else:\n",
    "                    frame1 = black_frame\n",
    "\n",
    "    concatenated_frame = cv2.vconcat([frame1, frame2])\n",
    "\n",
    "    out.write(concatenated_frame)\n",
    "    cv2.imshow('Concatenated Frame', concatenated_frame)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "## When everything done, release the capture\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd6f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
